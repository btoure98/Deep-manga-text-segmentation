{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9REkVvYmUFS"
      },
      "source": [
        "# **Checking runtime type**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EL-Wn4eIgL9f",
        "outputId": "84b65317-8436-4061-dc2c-b09e53a747d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K44kqg_pmiDv"
      },
      "source": [
        "# **Cloning repo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqTQ7DlgiGrk",
        "outputId": "6f0ffee4-2e9a-4230-92b0-da271d691bfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Deep-manga-text-segmentation'...\n",
            "remote: Enumerating objects: 64, done.\u001b[K\n",
            "remote: Counting objects: 100% (64/64), done.\u001b[K\n",
            "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
            "remote: Total 64 (delta 27), reused 57 (delta 20), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (64/64), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/btoure98/Deep-manga-text-segmentation.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOz26jrAihrt",
        "outputId": "a8ecb256-d504-45e3-9565-b484f345396e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Deep-manga-text-segmentation\n"
          ]
        }
      ],
      "source": [
        "%cd Deep-manga-text-segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IabzqoH4uQU3",
        "outputId": "6596d29b-3c09-46e7-ec24-1f55a09e64a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "!git pull"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzdlJT9cm10N"
      },
      "source": [
        "**Mounting gdrive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EinAV2-nKDV",
        "outputId": "dba6d042-4624-4d60-d4d0-bb53f4fc285f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THuYnk3Ymsa9"
      },
      "source": [
        "**Setup config**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_J56wb7fmRyk"
      },
      "outputs": [],
      "source": [
        "image = \"../gdrive/MyDrive/one_piece_test.png\"\n",
        "masks_destination = \"../gdrive/MyDrive/output_onepiece.png\"\n",
        "\n",
        "models = \"../gdrive/MyDrive/models/\"\n",
        "model_name = \"simple_Unet34.pth\"\n",
        "IMG_HEIGHT = 1024\n",
        "IMG_WIDTH = 1024\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_KWmenvrVxt"
      },
      "source": [
        "Dependencies install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YynjrEy2ratm",
        "outputId": "986a3807-f5cd-4238-a978-b66abb70ea25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting segmentation-models-pytorch\n",
            "  Downloading segmentation_models_pytorch-0.2.1-py3-none-any.whl (88 kB)\n",
            "\u001b[K     |████████████████████████████████| 88 kB 5.3 MB/s \n",
            "\u001b[?25hCollecting timm==0.4.12\n",
            "  Downloading timm-0.4.12-py3-none-any.whl (376 kB)\n",
            "\u001b[K     |████████████████████████████████| 376 kB 16.7 MB/s \n",
            "\u001b[?25hCollecting pretrainedmodels==0.7.4\n",
            "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 8.7 MB/s \n",
            "\u001b[?25hCollecting efficientnet-pytorch==0.6.3\n",
            "  Downloading efficientnet_pytorch-0.6.3.tar.gz (16 kB)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from segmentation-models-pytorch->-r requirements.txt (line 1)) (0.11.1+cu111)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet-pytorch==0.6.3->segmentation-models-pytorch->-r requirements.txt (line 1)) (1.10.0+cu111)\n",
            "Collecting munch\n",
            "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch->-r requirements.txt (line 1)) (4.63.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet-pytorch==0.6.3->segmentation-models-pytorch->-r requirements.txt (line 1)) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch->-r requirements.txt (line 1)) (1.21.5)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch->-r requirements.txt (line 1)) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from munch->pretrainedmodels==0.7.4->segmentation-models-pytorch->-r requirements.txt (line 1)) (1.15.0)\n",
            "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.6.3-py3-none-any.whl size=12421 sha256=abc008656e8a2cc0b6786d0db4f3451ae2a260bb4d7f925fecfb6ededb6d4359\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/6b/0c/f0ad36d00310e65390b0d4c9218ae6250ac579c92540c9097a\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60965 sha256=d3d20e4f554f0efd6ce96571288cecfc47be4ee6a5caaa9bb8a37be7e3e11cba\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/27/e8/9543d42de2740d3544db96aefef63bda3f2c1761b3334f4873\n",
            "Successfully built efficientnet-pytorch pretrainedmodels\n",
            "Installing collected packages: munch, timm, pretrainedmodels, efficientnet-pytorch, segmentation-models-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.6.3 munch-2.5.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.2.1 timm-0.4.12\n"
          ]
        }
      ],
      "source": [
        "!pip3 install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSdXGSID0d5B"
      },
      "source": [
        "IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "FkrWJ8Ne0c0M"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import segmentation_models_pytorch as smp\n",
        "import torch\n",
        "\n",
        "import cv2\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Rpp0SNsh9Bjc"
      },
      "outputs": [],
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVhvjDmC2WLw"
      },
      "source": [
        "**Evalution**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QjUdtrdKZOHN"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "# Create the model\n",
        "model = torch.load(models + model_name)\n",
        "model.eval()\n",
        "# Create the preprocessing transformation here\n",
        "transform = T.Compose([\n",
        "    T.ToPILImage(),\n",
        "    T.Resize((IMG_HEIGHT, IMG_WIDTH)),\n",
        "    T.ToTensor()])\n",
        "\n",
        "transform_mask = T.Compose([\n",
        "    T.ToPILImage(),\n",
        "    T.Grayscale(),\n",
        "    T.Resize((IMG_HEIGHT, IMG_WIDTH)),\n",
        "    T.ToTensor()])\n",
        "\n",
        "# load your image(s)\n",
        "img = cv2.imread(image)\n",
        "\n",
        "# Transform\n",
        "input = transform(img).to(DEVICE)\n",
        "\n",
        "# unsqueeze batch dimension, in case you are dealing with a single image\n",
        "input = input.unsqueeze(0)\n",
        "\n",
        "# Get prediction\n",
        "output = model(input).squeeze(0)\n",
        "#cv2.imwrite(masks_destination + img_name, output.squeeze(0).detach().cpu().numpy())\n",
        "save_image(output, masks_destination)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfd6ebzZ3xFA"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Predict.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}